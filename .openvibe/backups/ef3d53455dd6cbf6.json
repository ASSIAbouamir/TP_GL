{
  "id": "ef3d53455dd6cbf6",
  "filePath": "c:\\Users\\Hp\\Desktop\\TP_GL\\aarchitecture.md",
  "timestamp": 1764458929267,
  "originalContent": "# üìê Architecture et Pipeline Complet du Projet de G√©n√©ration d'√âcriture Manuscrite\r\n\r\n## üéØ Vue d'ensemble du Projet\r\n\r\nCe projet impl√©mente un **syst√®me de g√©n√©ration d'√©criture manuscrite** √† partir de texte, utilisant deux approches principales :\r\n1. **GAN Conditionnel (cGAN)** : G√©n√©ration d'images d'√©criture manuscrite via un r√©seau antagoniste g√©n√©ratif\r\n2. **Rendu bas√© sur polices** : G√©n√©ration stylis√©e utilisant des polices manuscrites avec effets r√©alistes\r\n\r\n---\r\n\r\n## üèóÔ∏è Architecture Globale\r\n\r\n```\r\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\r\n‚îÇ                    PIPELINE COMPLET DU PROJET                   ‚îÇ\r\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\r\n\r\n1. PR√âPARATION DES DONN√âES\r\n   ‚îÇ\r\n   ‚îú‚îÄ Dataset IAM (Images + Strokes + Transcriptions)\r\n   ‚îÇ\r\n   ‚îú‚îÄ prepare_data.py\r\n   ‚îÇ  ‚îú‚îÄ Extraction des strokes (traits) depuis XML\r\n   ‚îÇ  ‚îú‚îÄ Extraction des transcriptions ASCII\r\n   ‚îÇ  ‚îú‚îÄ Normalisation et pr√©processing\r\n   ‚îÇ  ‚îî‚îÄ Sauvegarde en format NumPy (.npy)\r\n   ‚îÇ\r\n   ‚îî‚îÄ data/processed/\r\n      ‚îú‚îÄ x.npy      (strokes: offsets dx, dy, eos)\r\n      ‚îú‚îÄ x_len.npy  (longueurs r√©elles)\r\n      ‚îú‚îÄ c.npy      (transcriptions encod√©es)\r\n      ‚îú‚îÄ c_len.npy  (longueurs de texte)\r\n      ‚îî‚îÄ w_id.npy   (IDs des √©crivains)\r\n\r\n2. ENTR√ÇINEMENT DU GAN\r\n   ‚îÇ\r\n   ‚îú‚îÄ GAN/dataset.py (IAMDataset)\r\n   ‚îÇ  ‚îî‚îÄ Conversion strokes ‚Üí images 128x128\r\n   ‚îÇ\r\n   ‚îú‚îÄ GAN/model.py\r\n   ‚îÇ  ‚îú‚îÄ Generator (ResNet-based)\r\n   ‚îÇ  ‚îÇ  ‚îî‚îÄ Input: [bruit(100) + texte_embed(20√ó128)] ‚Üí Image 128√ó128\r\n   ‚îÇ  ‚îÇ\r\n   ‚îÇ  ‚îî‚îÄ Discriminator (PatchGAN-like)\r\n   ‚îÇ     ‚îî‚îÄ Input: [image(128√ó128) + texte_embed] ‚Üí Score r√©el/faux\r\n   ‚îÇ\r\n   ‚îú‚îÄ GAN/train.py\r\n   ‚îÇ  ‚îú‚îÄ Boucle d'entra√Ænement adversarial\r\n   ‚îÇ  ‚îú‚îÄ Loss: MSE (LSGAN)\r\n   ‚îÇ  ‚îî‚îÄ Sauvegarde checkpoints + samples\r\n   ‚îÇ\r\n   ‚îî‚îÄ GAN/checkpoints/\r\n      ‚îú‚îÄ generator_X.pth\r\n      ‚îî‚îÄ discriminator_X.pth\r\n\r\n3. G√âN√âRATION & INF√âRENCE\r\n   ‚îÇ\r\n   ‚îú‚îÄ GAN/app.py (Streamlit)\r\n   ‚îÇ  ‚îî‚îÄ Interface web pour g√©n√©ration avec GAN entra√Æn√©\r\n   ‚îÇ\r\n   ‚îî‚îÄ handwriting_renderer.py\r\n      ‚îî‚îÄ Rendu stylis√© bas√© sur polices (alternative au GAN)\r\n\r\n4. √âVALUATION\r\n   ‚îÇ\r\n   ‚îú‚îÄ prepare_evaluation_data.py\r\n   ‚îÇ  ‚îî‚îÄ G√©n√®re paires (r√©el, g√©n√©r√©) pour m√©triques\r\n   ‚îÇ\r\n   ‚îú‚îÄ metrics.py\r\n   ‚îÇ  ‚îú‚îÄ FID, KID (qualit√© visuelle)\r\n   ‚îÇ  ‚îú‚îÄ CER, WER (reconnaissance de texte)\r\n   ‚îÇ  ‚îú‚îÄ SSIM, PSNR, LPIPS (similarit√©)\r\n   ‚îÇ  ‚îî‚îÄ OCR Accuracy\r\n   ‚îÇ\r\n   ‚îî‚îÄ evaluate_metrics.py\r\n      ‚îî‚îÄ Script d'√©valuation compl√®te\r\n```\r\n\r\n---\r\n\r\n## üìä Pipeline D√©taill√© √âtape par √âtape\r\n\r\n### **√âTAPE 1 : Pr√©paration des Donn√©es (`prepare_data.py`)**\r\n\r\n#### 1.1 V√©rification du Dataset IAM\r\n```python\r\ncheck_dataset_exists()\r\n```\r\n- V√©rifie la pr√©sence des r√©pertoires :\r\n  - `data/ascii/` : Transcriptions textuelles\r\n  - `data/lineStrokes/` : Fichiers de traits (strokes)\r\n  - `data/original-xml/` : M√©tadonn√©es XML\r\n\r\n#### 1.2 Collecte des Donn√©es\r\n```python\r\ncollect_data()\r\n```\r\n**Processus :**\r\n1. Parcourt r√©cursivement `data/ascii/` pour trouver tous les fichiers `.txt`\r\n2. Pour chaque fichier ASCII :\r\n   - Extrait le texte (transcription)\r\n   - Trouve le fichier XML correspondant dans `original-xml/`\r\n   - R√©cup√®re l'ID de l'√©crivain (`writerID`)\r\n   - Trouve les fichiers de strokes correspondants dans `lineStrokes/`\r\n3. Filtre les √©chantillons blacklist√©s (qualit√© faible)\r\n4. Retourne : `(stroke_fnames, transcriptions, writer_ids)`\r\n\r\n#### 1.3 Traitement des Strokes\r\n```python\r\nget_stroke_sequence(filename)\r\n```\r\n**Transformation :**\r\n```\r\nXML (coordonn√©es absolues)\r\n  ‚Üì\r\nCoordonn√©es (x, y, eos)\r\n  ‚Üì drawing.align()      ‚Üí Correction de l'inclinaison\r\n  ‚Üì drawing.denoise()     ‚Üí Lissage Savitzky-Golay\r\n  ‚Üì drawing.coords_to_offsets() ‚Üí Conversion en d√©placements\r\n  ‚Üì drawing.normalize()   ‚Üí Normalisation\r\n  ‚Üì\r\nOffsets normalis√©s [dx, dy, eos] (MAX_STROKE_LEN=1200)\r\n```\r\n\r\n**Format des offsets :**\r\n- `dx, dy` : D√©placements relatifs (normalis√©s)\r\n- `eos` : End-of-stroke (1 = fin de trait, 0 = continuation)\r\n\r\n#### 1.4 Traitement des Transcriptions\r\n```python\r\nget_ascii_sequences(filename)\r\n```\r\n**Processus :**\r\n1. Lit le fichier ASCII\r\n2. Extrait les lignes apr√®s `CSR:`\r\n3. Encode chaque caract√®re en index dans `drawing.alphabet`\r\n4. Tronque √† `MAX_CHAR_LEN=75` caract√®res\r\n\r\n#### 1.5 Sauvegarde\r\n```python\r\n# Tableaux NumPy cr√©√©s\r\nx = np.zeros([N, MAX_STROKE_LEN, 3])      # Strokes\r\nx_len = np.zeros([N])                      # Longueurs r√©elles\r\nc = np.zeros([N, MAX_CHAR_LEN])           # Transcriptions\r\nc_len = np.zeros([N])                      # Longueurs de texte\r\nw_id = np.zeros([N])                       # IDs √©crivains\r\n\r\n# Filtrage des √©chantillons valides\r\nvalid_mask = ~np.any(np.linalg.norm(x_i[:, :2], axis=1) > 60)\r\n\r\n# Sauvegarde\r\nnp.save('data/processed/x.npy', x[valid_mask])\r\nnp.save('data/processed/x_len.npy', x_len[valid_mask])\r\nnp.save('data/processed/c.npy', c[valid_mask])\r\nnp.save('data/processed/c_len.npy', c_len[valid_mask])\r\nnp.save('data/processed/w_id.npy', w_id[valid_mask])\r\n```\r\n\r\n---\r\n\r\n### **√âTAPE 2 : Dataset PyTorch (`GAN/dataset.py`)**\r\n\r\n#### 2.1 Chargement des Donn√©es\r\n```python\r\nIAMDataset(img_size=128, max_text_len=20)\r\n```\r\n- Charge les fichiers `.npy` depuis `data/processed/`\r\n- Filtre les textes > `max_text_len` caract√®res\r\n\r\n#### 2.2 Rendu Strokes ‚Üí Image\r\n```python\r\n__getitem__(idx)\r\n```\r\n\r\n**Processus de conversion :**\r\n\r\n1. **R√©cup√©ration des strokes**\r\n   ```python\r\n   strokes = x[real_idx][:stroke_len]  # (L, 3) : [dx, dy, eos]\r\n   ```\r\n\r\n2. **Conversion offsets ‚Üí coordonn√©es**\r\n   ```python\r\n   coords = np.cumsum(strokes[:, :2], axis=0)  # Accumulation des d√©placements\r\n   ```\r\n\r\n3. **Normalisation et centrage**\r\n   ```python\r\n   # Calcul des min/max\r\n   min_x, min_y = np.min(coords[:, 0]), np.min(coords[:, 1])\r\n   max_x, max_y = np.max(coords[:, 0]), np.max(coords[:, 1])\r\n   \r\n   # Scaling pour tenir dans 128√ó128 avec padding\r\n   scale = min(target_size / width, target_size / height)\r\n   coords = (coords - [min_x, min_y]) * scale + padding\r\n   ```\r\n\r\n4. **Dessin avec PIL**\r\n   ```python\r\n   img = Image.new('L', (128, 128), color=255)  # Fond blanc\r\n   draw = ImageDraw.Draw(img)\r\n   \r\n   # Dessine chaque trait (s√©par√© par eos=1)\r\n   for i in range(len(coords)):\r\n       if coords[i, 2] == 1:  # End of stroke\r\n           points = coords[start_idx:i+1, :2]\r\n           draw.line(points, fill=0, width=2)  # Noir\r\n   ```\r\n\r\n5. **Transformation**\r\n   ```python\r\n   transform = transforms.Compose([\r\n       transforms.ToTensor(),           # [0, 255] ‚Üí [0, 1]\r\n       transforms.Normalize((0.5,), (0.5,))  # [0, 1] ‚Üí [-1, 1]\r\n   ])\r\n   ```\r\n\r\n6. **Traitement du texte**\r\n   ```python\r\n   text = \"\".join([drawing.alphabet[i] for i in text_codes[:text_len]])\r\n   text_indices = [char_to_idx.get(c, 0) for c in text]\r\n   # Padding/truncation √† max_text_len=20\r\n   text_tensor = torch.tensor(text_indices, dtype=torch.long)\r\n   ```\r\n\r\n**Sortie :** `(img_tensor, text_tensor)`\r\n- `img_tensor` : `(1, 128, 128)` dans `[-1, 1]`\r\n- `text_tensor` : `(20,)` indices de caract√®res\r\n\r\n---\r\n\r\n### **√âTAPE 3 : Architecture du GAN (`GAN/model.py`)**\r\n\r\n#### 3.1 Generator (G√©n√©rateur)\r\n\r\n**Architecture :**\r\n\r\n```\r\nInput:\r\n  - noise: (B, 100)          # Vecteur de bruit al√©atoire\r\n  - text_indices: (B, 20)     # Indices de caract√®res\r\n\r\n1. Embedding du texte\r\n   text_embed = Embedding(vocab_size, 128)(text_indices)\r\n   ‚Üí (B, 20, 128)\r\n   \r\n2. Flatten\r\n   text_flat = text_embed.view(B, 20*128)\r\n   ‚Üí (B, 2560)\r\n   \r\n3. Concat√©nation\r\n   x = concat([noise(100), text_flat(2560)])\r\n   ‚Üí (B, 2660)\r\n   \r\n4. Fully Connected\r\n   fc = Linear(2660 ‚Üí 512*4*4)\r\n   ‚Üí (B, 8192)\r\n   reshape ‚Üí (B, 512, 4, 4)\r\n   \r\n5. Upsampling progressif\r\n   4√ó4 ‚Üí 8√ó8  (Upsample + Conv + BN + ReLU)\r\n   8√ó8 ‚Üí 16√ó16\r\n   16√ó16 ‚Üí 32√ó32\r\n   32√ó32 ‚Üí 64√ó64\r\n   64√ó64 ‚Üí 128√ó128 (Final: Conv + Tanh)\r\n\r\nOutput:\r\n  - gen_img: (B, 1, 128, 128) dans [-1, 1]\r\n```\r\n\r\n**Blocs ResNet :**\r\n- Chaque bloc contient : `Conv ‚Üí BN ‚Üí ReLU ‚Üí Conv ‚Üí BN`\r\n- Connexion r√©siduelle : `output = input + block(input)`\r\n\r\n#### 3.2 Discriminator (Discriminateur)\r\n\r\n**Architecture :**\r\n\r\n```\r\nInput:\r\n  - img: (B, 1, 128, 128)\r\n  - text_indices: (B, 20)\r\n\r\n1. Traitement de l'image (downsampling)\r\n   Conv2d(1 ‚Üí 64, stride=2)   ‚Üí (B, 64, 64)\r\n   Conv2d(64 ‚Üí 128, stride=2)  ‚Üí (B, 128, 32)\r\n   Conv2d(128 ‚Üí 256, stride=2) ‚Üí (B, 256, 16)\r\n   Conv2d(256 ‚Üí 512, stride=2)‚Üí (B, 512, 8)\r\n   \r\n2. Traitement du texte\r\n   text_embed = Embedding(vocab_size, 128)(text_indices)\r\n   ‚Üí (B, 20, 128)\r\n   text_flat = text_embed.view(B, 2560)\r\n   ‚Üí (B, 2560)\r\n   text_fc = Linear(2560 ‚Üí 512*8*8)\r\n   ‚Üí (B, 32768)\r\n   reshape ‚Üí (B, 512, 8, 8)\r\n   \r\n3. Fusion\r\n   combined = concat([img_features(512, 8, 8), text_features(512, 8, 8)])\r\n   ‚Üí (B, 1024, 8, 8)\r\n   \r\n4. Classification finale\r\n   Conv2d(1024 ‚Üí 512) ‚Üí (B, 512, 8, 8)\r\n   Conv2d(512 ‚Üí 1)     ‚Üí (B, 1, 4, 4)\r\n   Average pooling     ‚Üí (B, 1)\r\n   Sigmoid             ‚Üí Score [0, 1]\r\n\r\nOutput:\r\n  - score: (B, 1)  # Probabilit√© que l'image soit r√©elle\r\n```\r\n\r\n---\r\n\r\n### **√âTAPE 4 : Entra√Ænement (`GAN/train.py`)**\r\n\r\n#### 4.1 Initialisation\r\n```python\r\ngenerator = Generator(vocab_size, text_embedding_dim=128, noise_dim=100, max_text_len=20)\r\ndiscriminator = Discriminator(vocab_size, text_embedding_dim=128, max_text_len=20)\r\n\r\noptimizer_G = Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\r\noptimizer_D = Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\r\n\r\ncriterion = MSELoss()  # LSGAN loss\r\n```\r\n\r\n#### 4.2 Boucle d'Entra√Ænement\r\n\r\n**Pour chaque batch :**\r\n\r\n1. **Entra√Ænement du G√©n√©rateur**\r\n   ```python\r\n   # 1. G√©n√©rer des images\r\n   z = torch.randn(batch_size, 100)  # Bruit\r\n   gen_imgs = generator(z, text_indices)\r\n   \r\n   # 2. Calculer la loss\r\n   # Le g√©n√©rateur veut tromper le discriminateur\r\n   g_loss = MSELoss(discriminator(gen_imgs, text_indices), ones)\r\n   \r\n   # 3. Backpropagation\r\n   g_loss.backward()\r\n   optimizer_G.step()\r\n   ```\r\n\r\n2. **Entra√Ænement du Discriminateur**\r\n   ```python\r\n   # 1. Loss sur images r√©elles\r\n   real_loss = MSELoss(discriminator(real_imgs, text_indices), ones)\r\n   \r\n   # 2. Loss sur images g√©n√©r√©es\r\n   fake_loss = MSELoss(discriminator(gen_imgs.detach(), text_indices), zeros)\r\n   \r\n   # 3. Loss totale\r\n   d_loss = 0.5 * (real_loss + fake_loss)\r\n   \r\n   # 4. Backpropagation\r\n   d_loss.backward()\r\n   optimizer_D.step()\r\n   ```\r\n\r\n3. **Sauvegarde**\r\n   - Tous les 5 epochs : checkpoints\r\n   - Chaque epoch : √©chantillons g√©n√©r√©s dans `GAN/samples/`\r\n\r\n---\r\n\r\n### **√âTAPE 5 : G√©n√©ration (Inference)**\r\n\r\n#### 5.1 Avec le GAN (`GAN/app.py`)\r\n```python\r\n# 1. Charger le mod√®le entra√Æn√©\r\ngenerator.load_state_dict(torch.load('checkpoint.pth'))\r\n\r\n# 2. Pr√©parer les inputs\r\ntext = \"Hello World\"\r\ntext_indices = [char_to_idx[c] for c in text]  # Padding √† 20\r\nz = torch.randn(1, 100)  # Bruit\r\n\r\n# 3. G√©n√©rer\r\nwith torch.no_grad():\r\n    gen_img = generator(z, text_tensor)\r\n\r\n# 4. Post-processing\r\nimg = (gen_img + 1) / 2.0  # [-1, 1] ‚Üí [0, 1]\r\nimg = img * 255  # [0, 1] ‚Üí [0, 255]\r\n```\r\n\r\n#### 5.2 Avec le Rendu Stylis√© (`handwriting_renderer.py`)\r\n```python\r\nrenderer = HandwritingRenderer(RenderConfig())\r\n\r\nimage = renderer.render(\r\n    text=\"Hello World\",\r\n    font_name=\"Segoe Script\",\r\n    font_size=64,\r\n    ink_color=(32, 32, 32),\r\n    paper_style=\"plain\",\r\n    jitter_px=1.4,      # Tremblement\r\n    tilt_degrees=-3.0,   # Inclinaison\r\n    noise_strength=0.08, # Texture papier\r\n    line_spacing=1.35\r\n)\r\n```\r\n\r\n**Processus de rendu :**\r\n1. Cr√©ation d'une image blanche\r\n2. Dessin du texte avec la police s√©lectionn√©e\r\n3. Application du jitter (d√©placement al√©atoire des caract√®res)\r\n4. Application de l'inclinaison (transformation affine)\r\n5. Ajout d'ombre (Gaussian blur)\r\n6. Ajout de bruit (texture papier)\r\n\r\n---\r\n\r\n### **√âTAPE 6 : √âvaluation (`metrics.py`, `evaluate_metrics.py`)**\r\n\r\n#### 6.1 Pr√©paration des Donn√©es d'√âvaluation\r\n```python\r\nprepare_evaluation_data(num_samples=50)\r\n```\r\n\r\n**G√©n√®re deux ensembles :**\r\n- `evaluation/real/` : Images rendues depuis les strokes r√©els\r\n- `evaluation/gen/` : Images g√©n√©r√©es (GAN ou rendu stylis√©)\r\n\r\n#### 6.2 M√©triques Calcul√©es\r\n\r\n**1. FID (Fr√©chet Inception Distance)**\r\n- Mesure la distance entre distributions d'images r√©elles et g√©n√©r√©es\r\n- Utilise Inception v3 pour extraire des features\r\n- Plus bas = meilleur (typiquement < 50)\r\n\r\n**2. KID (Kernel Inception Distance)**\r\n- Version non-biais√©e du FID\r\n- Utilise un kernel polynomial\r\n- Plus bas = meilleur\r\n\r\n**3. CER (Character Error Rate)**\r\n- Taux d'erreur au niveau des caract√®res\r\n- Utilise la distance de Levenshtein\r\n- 0.0 = parfait, 1.0 = toutes erreurs\r\n\r\n**4. WER (Word Error Rate)**\r\n- Taux d'erreur au niveau des mots\r\n- 0.0 = parfait, 1.0 = toutes erreurs\r\n\r\n**5. SSIM (Structural Similarity Index)**\r\n- Similarit√© structurelle entre images\r\n- 1.0 = identique, 0.0 = compl√®tement diff√©rent\r\n\r\n**6. PSNR (Peak Signal-to-Noise Ratio)**\r\n- Ratio signal/bruit\r\n- Plus haut = meilleur (typiquement 20-50 dB)\r\n\r\n**7. LPIPS (Learned Perceptual Image Patch Similarity)**\r\n- Similarit√© perceptuelle apprise\r\n- Plus bas = meilleur (0.0 = identique)\r\n\r\n**8. OCR Accuracy**\r\n- Pourcentage de caract√®res correctement reconnus par OCR\r\n- 1.0 = 100% correct\r\n\r\n---\r\n\r\n## üîÑ Flux de Donn√©es Complet\r\n\r\n```\r\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\r\n‚îÇ                    FLUX DE DONN√âES                          ‚îÇ\r\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\r\n\r\n1. DONN√âES BRUTES (IAM Dataset)\r\n   ‚îÇ\r\n   ‚îú‚îÄ XML Files (strokes)\r\n   ‚îÇ  ‚îî‚îÄ Coordonn√©es absolues (x, y, eos)\r\n   ‚îÇ\r\n   ‚îú‚îÄ ASCII Files (transcriptions)\r\n   ‚îÇ  ‚îî‚îÄ Texte brut\r\n   ‚îÇ\r\n   ‚îî‚îÄ Metadata (writer IDs)\r\n      ‚îî‚îÄ Identifiants √©crivains\r\n\r\n2. PR√âTRAITEMENT (prepare_data.py)\r\n   ‚îÇ\r\n   ‚îú‚îÄ Strokes\r\n   ‚îÇ  ‚îî‚îÄ XML ‚Üí Offsets normalis√©s [dx, dy, eos]\r\n   ‚îÇ\r\n   ‚îú‚îÄ Textes\r\n   ‚îÇ  ‚îî‚îÄ ASCII ‚Üí Indices dans alphabet\r\n   ‚îÇ\r\n   ‚îî‚îÄ Sauvegarde\r\n      ‚îî‚îÄ NumPy arrays (.npy)\r\n\r\n3. DATASET PYTORCH (GAN/dataset.py)\r\n   ‚îÇ\r\n   ‚îú‚îÄ Chargement .npy\r\n   ‚îÇ\r\n   ‚îú‚îÄ Conversion strokes ‚Üí images 128√ó128\r\n   ‚îÇ  ‚îî‚îÄ PIL ImageDraw\r\n   ‚îÇ\r\n   ‚îî‚îÄ Transformation\r\n      ‚îî‚îÄ Tensor + Normalisation [-1, 1]\r\n\r\n4. ENTRA√éNEMENT (GAN/train.py)\r\n   ‚îÇ\r\n   ‚îú‚îÄ Batch: (images, text_indices)\r\n   ‚îÇ\r\n   ‚îú‚îÄ Generator\r\n   ‚îÇ  ‚îî‚îÄ [noise + text] ‚Üí image g√©n√©r√©e\r\n   ‚îÇ\r\n   ‚îú‚îÄ Discriminator\r\n   ‚îÇ  ‚îî‚îÄ [image + text] ‚Üí score r√©el/faux\r\n   ‚îÇ\r\n   ‚îî‚îÄ Loss & Backprop\r\n      ‚îî‚îÄ Mise √† jour des poids\r\n\r\n5. INF√âRENCE\r\n   ‚îÇ\r\n   ‚îú‚îÄ GAN (GAN/app.py)\r\n   ‚îÇ  ‚îî‚îÄ Texte ‚Üí Image via mod√®le entra√Æn√©\r\n   ‚îÇ\r\n   ‚îî‚îÄ Rendu stylis√© (handwriting_renderer.py)\r\n      ‚îî‚îÄ Texte ‚Üí Image via polices + effets\r\n\r\n6. √âVALUATION\r\n   ‚îÇ\r\n   ‚îú‚îÄ G√©n√©ration de paires (r√©el, g√©n√©r√©)\r\n   ‚îÇ\r\n   ‚îú‚îÄ Calcul m√©triques\r\n   ‚îÇ  ‚îú‚îÄ FID, KID (qualit√© visuelle)\r\n   ‚îÇ  ‚îú‚îÄ CER, WER (reconnaissance)\r\n   ‚îÇ  ‚îî‚îÄ SSIM, PSNR, LPIPS (similarit√©)\r\n   ‚îÇ\r\n   ‚îî‚îÄ Rapport JSON\r\n```\r\n\r\n---\r\n\r\n## üìÅ Structure des Fichiers\r\n\r\n```\r\nGEN - Copie/\r\n‚îÇ\r\n‚îú‚îÄ‚îÄ data/\r\n‚îÇ   ‚îú‚îÄ‚îÄ raw/                    # Dataset IAM brut\r\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ascii/\r\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ lineStrokes/\r\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ original-xml/\r\n‚îÇ   ‚îÇ\r\n‚îÇ   ‚îî‚îÄ‚îÄ processed/              # Donn√©es pr√©process√©es\r\n‚îÇ       ‚îú‚îÄ‚îÄ x.npy               # Strokes\r\n‚îÇ       ‚îú‚îÄ‚îÄ x_len.npy           # Longueurs strokes\r\n‚îÇ       ‚îú‚îÄ‚îÄ c.npy               # Transcriptions\r\n‚îÇ       ‚îú‚îÄ‚îÄ c_len.npy           # Longueurs textes\r\n‚îÇ       ‚îî‚îÄ‚îÄ w_id.npy            # IDs √©crivains\r\n‚îÇ\r\n‚îú‚îÄ‚îÄ GAN/\r\n‚îÇ   ‚îú‚îÄ‚îÄ model.py                # Generator + Discriminator\r\n‚îÇ   ‚îú‚îÄ‚îÄ dataset.py              # IAMDataset PyTorch\r\n‚îÇ   ‚îú‚îÄ‚îÄ train.py                # Script d'entra√Ænement\r\n‚îÇ   ‚îú‚îÄ‚îÄ app.py                  # Interface Streamlit GAN\r\n‚îÇ   ‚îú‚îÄ‚îÄ checkpoints/            # Mod√®les entra√Æn√©s\r\n‚îÇ   ‚îî‚îÄ‚îÄ samples/                # √âchantillons g√©n√©r√©s\r\n‚îÇ\r\n‚îú‚îÄ‚îÄ evaluation/\r\n‚îÇ   ‚îú‚îÄ‚îÄ real/                   # Images r√©elles\r\n‚îÇ   ‚îî‚îÄ‚îÄ gen/                   # Images g√©n√©r√©es\r\n‚îÇ\r\n‚îú‚îÄ‚îÄ prepare_data.py             # Pr√©paration dataset IAM\r\n‚îú‚îÄ‚îÄ drawing.py                  # Utilitaires de rendu strokes\r\n‚îú‚îÄ‚îÄ handwriting_renderer.py    # Rendu stylis√© (polices)\r\n‚îú‚îÄ‚îÄ metrics.py                  # M√©triques d'√©valuation\r\n‚îú‚îÄ‚îÄ evaluate_metrics.py         # Script d'√©valuation\r\n‚îú‚îÄ‚îÄ prepare_evaluation_data.py  # Pr√©paration donn√©es √©valuation\r\n‚îú‚îÄ‚îÄ check_data_rendering.py     # V√©rification rendu\r\n‚îÇ\r\n‚îî‚îÄ‚îÄ streamlit_app.py            # Interface principale (rendu stylis√©)\r\n```\r\n\r\n---\r\n\r\n## üéØ Points Cl√©s de l'Architecture\r\n\r\n### 1. **Repr√©sentation des Strokes**\r\n- Format : Offsets normalis√©s `[dx, dy, eos]`\r\n- Avantages :\r\n  - Invariant √† la translation\r\n  - Normalis√© pour stabilit√©\r\n  - Compact (1200 points max)\r\n\r\n### 2. **Conditionnement du GAN**\r\n- Le texte est embedd√© et concat√©n√© au bruit\r\n- Le discriminateur re√ßoit aussi le texte\r\n- Permet un contr√¥le pr√©cis de la g√©n√©ration\r\n\r\n### 3. **Rendu On-the-Fly**\r\n- Les strokes sont convertis en images √† la vol√©e dans le dataset\r\n- √âvite de stocker des milliers d'images\r\n- Permet des transformations dynamiques\r\n\r\n### 4. **Deux Approches Compl√©mentaires**\r\n- **GAN** : Apprentissage profond, style variable\r\n- **Rendu stylis√©** : Contr√¥le pr√©cis, rapide, pas d'entra√Ænement\r\n\r\n### 5. **√âvaluation Multi-M√©triques**\r\n- Qualit√© visuelle (FID, KID)\r\n- Reconnaissance (CER, WER, OCR)\r\n- Similarit√© (SSIM, PSNR, LPIPS)\r\n\r\n---\r\n\r\n## üöÄ Workflow Typique\r\n\r\n### **Entra√Ænement d'un nouveau mod√®le :**\r\n```bash\r\n# 1. Pr√©parer les donn√©es\r\npython prepare_data.py\r\n\r\n# 2. V√©rifier le rendu\r\npython check_data_rendering.py\r\n\r\n# 3. Entra√Æner le GAN\r\ncd GAN\r\npython train.py --epochs 100 --batch_size 16\r\n\r\n# 4. G√©n√©rer des √©chantillons\r\n# (automatique pendant l'entra√Ænement)\r\n```\r\n\r\n### **√âvaluation :**\r\n```bash\r\n# 1. Pr√©parer les donn√©es d'√©valuation\r\npython prepare_evaluation_data.py\r\n\r\n# 2. Calculer les m√©triques\r\npython evaluate_metrics.py \\\r\n    --real_dir evaluation/real \\\r\n    --gen_dir evaluation/gen \\\r\n    --output metrics_results.json\r\n```\r\n\r\n### **Utilisation :**\r\n```bash\r\n# Interface Streamlit (rendu stylis√©)\r\nstreamlit run streamlit_app.py\r\n\r\n# Interface GAN (si mod√®le entra√Æn√©)\r\nstreamlit run GAN/app.py\r\n```\r\n\r\n---\r\n\r\n## üìà Hyperparam√®tres Principaux\r\n\r\n| Param√®tre | Valeur | Description |\r\n|-----------|--------|-------------|\r\n| `image_size` | 128√ó128 | Taille des images g√©n√©r√©es |\r\n| `latent_dim` | 100 | Dimension du vecteur de bruit |\r\n| `text_embedding_dim` | 128 | Dimension de l'embedding texte |\r\n| `max_text_len` | 20 | Longueur maximale du texte |\r\n| `vocab_size` | ~70 | Taille de l'alphabet |\r\n| `MAX_STROKE_LEN` | 1200 | Longueur max des s√©quences de strokes |\r\n| `MAX_CHAR_LEN` | 75 | Longueur max des transcriptions |\r\n| `learning_rate` | 0.0002 | Taux d'apprentissage |\r\n| `batch_size` | 16 | Taille des batches |\r\n\r\n---\r\n\r\n## üîç D√©tails Techniques\r\n\r\n### **Normalisation des Strokes**\r\n- Les offsets sont normalis√©s par la m√©diane de leur norme\r\n- √âvite les probl√®mes d'√©chelle\r\n- Rend l'entra√Ænement plus stable\r\n\r\n### **Padding et Truncation**\r\n- Strokes : Padding avec `[0, 0, 0]` jusqu'√† `MAX_STROKE_LEN`\r\n- Textes : Padding avec `0` (caract√®re nul) jusqu'√† `max_text_len`\r\n- Les longueurs r√©elles sont stock√©es s√©par√©ment\r\n\r\n### **Loss Function (LSGAN)**\r\n- Utilise MSE au lieu de BCE\r\n- Plus stable pour l'entra√Ænement\r\n- Labels : `1` pour r√©el, `0` pour faux\r\n\r\n### **Data Augmentation**\r\n- Pas d'augmentation explicite dans le code actuel\r\n- Possibilit√© d'ajouter : rotation, scaling, noise\r\n\r\n---\r\n\r\n## üéì Conclusion\r\n\r\nCe projet impl√©mente un pipeline complet de g√©n√©ration d'√©criture manuscrite, de la pr√©paration des donn√©es √† l'√©valuation, avec deux approches compl√©mentaires (GAN et rendu stylis√©) et une suite compl√®te de m√©triques d'√©valuation.\r\n\r\n",
  "toolName": "auto-backup",
  "toolInput": {
    "file_path": "aarchitecture.md",
    "trigger": "local-change"
  },
  "metadata": {
    "lineCount": 698,
    "characterCount": 19531,
    "fileSize": 21170,
    "language": "markdown",
    "mimeType": "text/plain",
    "contentHash": "08d07262482f1898088e81554fa9f778709edeee83ed4eb6010b0af51c2fedb4"
  },
  "backupType": "auto-local-change",
  "checkpointLabel": "File modified: aarchitecture.md"
}