# üìê Architecture et Pipeline Complet du Projet de G√©n√©ration d'√âcriture Manuscrite

## üéØ Vue d'ensemble du Projet

Ce projet impl√©mente un **syst√®me de g√©n√©ration d'√©criture manuscrite** √† partir de texte, utilisant deux approches principales :
1. **GAN Conditionnel (cGAN)** : G√©n√©ration d'images d'√©criture manuscrite via un r√©seau antagoniste g√©n√©ratif
2. **Rendu bas√© sur polices** : G√©n√©ration stylis√©e utilisant des polices manuscrites avec effets r√©alistes

---

## üèóÔ∏è Architecture Globale

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    PIPELINE COMPLET DU PROJET                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

1. PR√âPARATION DES DONN√âES
   ‚îÇ
   ‚îú‚îÄ Dataset IAM (Images + Strokes + Transcriptions)
   ‚îÇ
   ‚îú‚îÄ prepare_data.py
   ‚îÇ  ‚îú‚îÄ Extraction des strokes (traits) depuis XML
   ‚îÇ  ‚îú‚îÄ Extraction des transcriptions ASCII
   ‚îÇ  ‚îú‚îÄ Normalisation et pr√©processing
   ‚îÇ  ‚îî‚îÄ Sauvegarde en format NumPy (.npy)
   ‚îÇ
   ‚îî‚îÄ data/processed/
      ‚îú‚îÄ x.npy      (strokes: offsets dx, dy, eos)
      ‚îú‚îÄ x_len.npy  (longueurs r√©elles)
      ‚îú‚îÄ c.npy      (transcriptions encod√©es)
      ‚îú‚îÄ c_len.npy  (longueurs de texte)
      ‚îî‚îÄ w_id.npy   (IDs des √©crivains)

2. ENTR√ÇINEMENT DU GAN
   ‚îÇ
   ‚îú‚îÄ GAN/dataset.py (IAMDataset)
   ‚îÇ  ‚îî‚îÄ Conversion strokes ‚Üí images 128x128
   ‚îÇ
   ‚îú‚îÄ GAN/model.py
   ‚îÇ  ‚îú‚îÄ Generator (ResNet-based)
   ‚îÇ  ‚îÇ  ‚îî‚îÄ Input: [bruit(100) + texte_embed(20√ó128)] ‚Üí Image 128√ó128
   ‚îÇ  ‚îÇ
   ‚îÇ  ‚îî‚îÄ Discriminator (PatchGAN-like)
   ‚îÇ     ‚îî‚îÄ Input: [image(128√ó128) + texte_embed] ‚Üí Score r√©el/faux
   ‚îÇ
   ‚îú‚îÄ GAN/train.py
   ‚îÇ  ‚îú‚îÄ Boucle d'entra√Ænement adversarial
   ‚îÇ  ‚îú‚îÄ Loss: MSE (LSGAN)
   ‚îÇ  ‚îî‚îÄ Sauvegarde checkpoints + samples
   ‚îÇ
   ‚îî‚îÄ GAN/checkpoints/
      ‚îú‚îÄ generator_X.pth
      ‚îî‚îÄ discriminator_X.pth

3. G√âN√âRATION & INF√âRENCE
   ‚îÇ
   ‚îú‚îÄ GAN/app.py (Streamlit)
   ‚îÇ  ‚îî‚îÄ Interface web pour g√©n√©ration avec GAN entra√Æn√©
   ‚îÇ
   ‚îî‚îÄ handwriting_renderer.py
      ‚îî‚îÄ Rendu stylis√© bas√© sur polices (alternative au GAN)

4. √âVALUATION
   ‚îÇ
   ‚îú‚îÄ prepare_evaluation_data.py
   ‚îÇ  ‚îî‚îÄ G√©n√®re paires (r√©el, g√©n√©r√©) pour m√©triques
   ‚îÇ
   ‚îú‚îÄ metrics.py
   ‚îÇ  ‚îú‚îÄ FID, KID (qualit√© visuelle)
   ‚îÇ  ‚îú‚îÄ CER, WER (reconnaissance de texte)
   ‚îÇ  ‚îú‚îÄ SSIM, PSNR, LPIPS (similarit√©)
   ‚îÇ  ‚îî‚îÄ OCR Accuracy
   ‚îÇ
   ‚îî‚îÄ evaluate_metrics.py
      ‚îî‚îÄ Script d'√©valuation compl√®te
```

---

## üìä Pipeline D√©taill√© √âtape par √âtape

### **√âTAPE 1 : Pr√©paration des Donn√©es (`prepare_data.py`)**

#### 1.1 V√©rification du Dataset IAM
```python
check_dataset_exists()
```
- V√©rifie la pr√©sence des r√©pertoires :
  - `data/ascii/` : Transcriptions textuelles
  - `data/lineStrokes/` : Fichiers de traits (strokes)
  - `data/original-xml/` : M√©tadonn√©es XML

#### 1.2 Collecte des Donn√©es
```python
collect_data()
```
**Processus :**
1. Parcourt r√©cursivement `data/ascii/` pour trouver tous les fichiers `.txt`
2. Pour chaque fichier ASCII :
   - Extrait le texte (transcription)
   - Trouve le fichier XML correspondant dans `original-xml/`
   - R√©cup√®re l'ID de l'√©crivain (`writerID`)
   - Trouve les fichiers de strokes correspondants dans `lineStrokes/`
3. Filtre les √©chantillons blacklist√©s (qualit√© faible)
4. Retourne : `(stroke_fnames, transcriptions, writer_ids)`

#### 1.3 Traitement des Strokes
```python
get_stroke_sequence(filename)
```
**Transformation :**
```
XML (coordonn√©es absolues)
  ‚Üì
Coordonn√©es (x, y, eos)
  ‚Üì drawing.align()      ‚Üí Correction de l'inclinaison
  ‚Üì drawing.denoise()     ‚Üí Lissage Savitzky-Golay
  ‚Üì drawing.coords_to_offsets() ‚Üí Conversion en d√©placements
  ‚Üì drawing.normalize()   ‚Üí Normalisation
  ‚Üì
Offsets normalis√©s [dx, dy, eos] (MAX_STROKE_LEN=1200)
```

**Format des offsets :**
- `dx, dy` : D√©placements relatifs (normalis√©s)
- `eos` : End-of-stroke (1 = fin de trait, 0 = continuation)

#### 1.4 Traitement des Transcriptions
```python
get_ascii_sequences(filename)
```
**Processus :**
1. Lit le fichier ASCII
2. Extrait les lignes apr√®s `CSR:`
3. Encode chaque caract√®re en index dans `drawing.alphabet`
4. Tronque √† `MAX_CHAR_LEN=75` caract√®res

#### 1.5 Sauvegarde
```python
# Tableaux NumPy cr√©√©s
x = np.zeros([N, MAX_STROKE_LEN, 3])      # Strokes
x_len = np.zeros([N])                      # Longueurs r√©elles
c = np.zeros([N, MAX_CHAR_LEN])           # Transcriptions
c_len = np.zeros([N])                      # Longueurs de texte
w_id = np.zeros([N])                       # IDs √©crivains

# Filtrage des √©chantillons valides
valid_mask = ~np.any(np.linalg.norm(x_i[:, :2], axis=1) > 60)

# Sauvegarde
np.save('data/processed/x.npy', x[valid_mask])
np.save('data/processed/x_len.npy', x_len[valid_mask])
np.save('data/processed/c.npy', c[valid_mask])
np.save('data/processed/c_len.npy', c_len[valid_mask])
np.save('data/processed/w_id.npy', w_id[valid_mask])
```

---

### **√âTAPE 2 : Dataset PyTorch (`GAN/dataset.py`)**

#### 2.1 Chargement des Donn√©es
```python
IAMDataset(img_size=128, max_text_len=20)
```
- Charge les fichiers `.npy` depuis `data/processed/`
- Filtre les textes > `max_text_len` caract√®res

#### 2.2 Rendu Strokes ‚Üí Image
```python
__getitem__(idx)
```

**Processus de conversion :**

1. **R√©cup√©ration des strokes**
   ```python
   strokes = x[real_idx][:stroke_len]  # (L, 3) : [dx, dy, eos]
   ```

2. **Conversion offsets ‚Üí coordonn√©es**
   ```python
   coords = np.cumsum(strokes[:, :2], axis=0)  # Accumulation des d√©placements
   ```

3. **Normalisation et centrage**
   ```python
   # Calcul des min/max
   min_x, min_y = np.min(coords[:, 0]), np.min(coords[:, 1])
   max_x, max_y = np.max(coords[:, 0]), np.max(coords[:, 1])
   
   # Scaling pour tenir dans 128√ó128 avec padding
   scale = min(target_size / width, target_size / height)
   coords = (coords - [min_x, min_y]) * scale + padding
   ```

4. **Dessin avec PIL**
   ```python
   img = Image.new('L', (128, 128), color=255)  # Fond blanc
   draw = ImageDraw.Draw(img)
   
   # Dessine chaque trait (s√©par√© par eos=1)
   for i in range(len(coords)):
       if coords[i, 2] == 1:  # End of stroke
           points = coords[start_idx:i+1, :2]
           draw.line(points, fill=0, width=2)  # Noir
   ```

5. **Transformation**
   ```python
   transform = transforms.Compose([
       transforms.ToTensor(),           # [0, 255] ‚Üí [0, 1]
       transforms.Normalize((0.5,), (0.5,))  # [0, 1] ‚Üí [-1, 1]
   ])
   ```

6. **Traitement du texte**
   ```python
   text = "".join([drawing.alphabet[i] for i in text_codes[:text_len]])
   text_indices = [char_to_idx.get(c, 0) for c in text]
   # Padding/truncation √† max_text_len=20
   text_tensor = torch.tensor(text_indices, dtype=torch.long)
   ```

**Sortie :** `(img_tensor, text_tensor)`
- `img_tensor` : `(1, 128, 128)` dans `[-1, 1]`
- `text_tensor` : `(20,)` indices de caract√®res

---

### **√âTAPE 3 : Architecture du GAN (`GAN/model.py`)**

#### 3.1 Generator (G√©n√©rateur)

**Architecture :**

```
Input:
  - noise: (B, 100)          # Vecteur de bruit al√©atoire
  - text_indices: (B, 20)     # Indices de caract√®res

1. Embedding du texte
   text_embed = Embedding(vocab_size, 128)(text_indices)
   ‚Üí (B, 20, 128)
   
2. Flatten
   text_flat = text_embed.view(B, 20*128)
   ‚Üí (B, 2560)
   
3. Concat√©nation
   x = concat([noise(100), text_flat(2560)])
   ‚Üí (B, 2660)
   
4. Fully Connected
   fc = Linear(2660 ‚Üí 512*4*4)
   ‚Üí (B, 8192)
   reshape ‚Üí (B, 512, 4, 4)
   
5. Upsampling progressif
   4√ó4 ‚Üí 8√ó8  (Upsample + Conv + BN + ReLU)
   8√ó8 ‚Üí 16√ó16
   16√ó16 ‚Üí 32√ó32
   32√ó32 ‚Üí 64√ó64
   64√ó64 ‚Üí 128√ó128 (Final: Conv + Tanh)

Output:
  - gen_img: (B, 1, 128, 128) dans [-1, 1]
```

**Blocs ResNet :**
- Chaque bloc contient : `Conv ‚Üí BN ‚Üí ReLU ‚Üí Conv ‚Üí BN`
- Connexion r√©siduelle : `output = input + block(input)`

#### 3.2 Discriminator (Discriminateur)

**Architecture :**

```
Input:
  - img: (B, 1, 128, 128)
  - text_indices: (B, 20)

1. Traitement de l'image (downsampling)
   Conv2d(1 ‚Üí 64, stride=2)   ‚Üí (B, 64, 64)
   Conv2d(64 ‚Üí 128, stride=2)  ‚Üí (B, 128, 32)
   Conv2d(128 ‚Üí 256, stride=2) ‚Üí (B, 256, 16)
   Conv2d(256 ‚Üí 512, stride=2)‚Üí (B, 512, 8)
   
2. Traitement du texte
   text_embed = Embedding(vocab_size, 128)(text_indices)
   ‚Üí (B, 20, 128)
   text_flat = text_embed.view(B, 2560)
   ‚Üí (B, 2560)
   text_fc = Linear(2560 ‚Üí 512*8*8)
   ‚Üí (B, 32768)
   reshape ‚Üí (B, 512, 8, 8)
   
3. Fusion
   combined = concat([img_features(512, 8, 8), text_features(512, 8, 8)])
   ‚Üí (B, 1024, 8, 8)
   
4. Classification finale
   Conv2d(1024 ‚Üí 512) ‚Üí (B, 512, 8, 8)
   Conv2d(512 ‚Üí 1)     ‚Üí (B, 1, 4, 4)
   Average pooling     ‚Üí (B, 1)
   Sigmoid             ‚Üí Score [0, 1]

Output:
  - score: (B, 1)  # Probabilit√© que l'image soit r√©elle
```

---

### **√âTAPE 4 : Entra√Ænement (`GAN/train.py`)**

#### 4.1 Initialisation
```python
generator = Generator(vocab_size, text_embedding_dim=128, noise_dim=100, max_text_len=20)
discriminator = Discriminator(vocab_size, text_embedding_dim=128, max_text_len=20)

optimizer_G = Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))
optimizer_D = Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))

criterion = MSELoss()  # LSGAN loss
```

#### 4.2 Boucle d'Entra√Ænement

**Pour chaque batch :**

1. **Entra√Ænement du G√©n√©rateur**
   ```python
   # 1. G√©n√©rer des images
   z = torch.randn(batch_size, 100)  # Bruit
   gen_imgs = generator(z, text_indices)
   
   # 2. Calculer la loss
   # Le g√©n√©rateur veut tromper le discriminateur
   g_loss = MSELoss(discriminator(gen_imgs, text_indices), ones)
   
   # 3. Backpropagation
   g_loss.backward()
   optimizer_G.step()
   ```

2. **Entra√Ænement du Discriminateur**
   ```python
   # 1. Loss sur images r√©elles
   real_loss = MSELoss(discriminator(real_imgs, text_indices), ones)
   
   # 2. Loss sur images g√©n√©r√©es
   fake_loss = MSELoss(discriminator(gen_imgs.detach(), text_indices), zeros)
   
   # 3. Loss totale
   d_loss = 0.5 * (real_loss + fake_loss)
   
   # 4. Backpropagation
   d_loss.backward()
   optimizer_D.step()
   ```

3. **Sauvegarde**
   - Tous les 5 epochs : checkpoints
   - Chaque epoch : √©chantillons g√©n√©r√©s dans `GAN/samples/`

---

### **√âTAPE 5 : G√©n√©ration (Inference)**

#### 5.1 Avec le GAN (`GAN/app.py`)
```python
# 1. Charger le mod√®le entra√Æn√©
generator.load_state_dict(torch.load('checkpoint.pth'))

# 2. Pr√©parer les inputs
text = "Hello World"
text_indices = [char_to_idx[c] for c in text]  # Padding √† 20
z = torch.randn(1, 100)  # Bruit

# 3. G√©n√©rer
with torch.no_grad():
    gen_img = generator(z, text_tensor)

# 4. Post-processing
img = (gen_img + 1) / 2.0  # [-1, 1] ‚Üí [0, 1]
img = img * 255  # [0, 1] ‚Üí [0, 255]
```

#### 5.2 Avec le Rendu Stylis√© (`handwriting_renderer.py`)
```python
renderer = HandwritingRenderer(RenderConfig())

image = renderer.render(
    text="Hello World",
    font_name="Segoe Script",
    font_size=64,
    ink_color=(32, 32, 32),
    paper_style="plain",
    jitter_px=1.4,      # Tremblement
    tilt_degrees=-3.0,   # Inclinaison
    noise_strength=0.08, # Texture papier
    line_spacing=1.35
)
```

**Processus de rendu :**
1. Cr√©ation d'une image blanche
2. Dessin du texte avec la police s√©lectionn√©e
3. Application du jitter (d√©placement al√©atoire des caract√®res)
4. Application de l'inclinaison (transformation affine)
5. Ajout d'ombre (Gaussian blur)
6. Ajout de bruit (texture papier)

---

### **√âTAPE 6 : √âvaluation (`metrics.py`, `evaluate_metrics.py`)**

#### 6.1 Pr√©paration des Donn√©es d'√âvaluation
```python
prepare_evaluation_data(num_samples=50)
```

**G√©n√®re deux ensembles :**
- `evaluation/real/` : Images rendues depuis les strokes r√©els
- `evaluation/gen/` : Images g√©n√©r√©es (GAN ou rendu stylis√©)

#### 6.2 M√©triques Calcul√©es

**1. FID (Fr√©chet Inception Distance)**
- Mesure la distance entre distributions d'images r√©elles et g√©n√©r√©es
- Utilise Inception v3 pour extraire des features
- Plus bas = meilleur (typiquement < 50)

**2. KID (Kernel Inception Distance)**
- Version non-biais√©e du FID
- Utilise un kernel polynomial
- Plus bas = meilleur

**3. CER (Character Error Rate)**
- Taux d'erreur au niveau des caract√®res
- Utilise la distance de Levenshtein
- 0.0 = parfait, 1.0 = toutes erreurs

**4. WER (Word Error Rate)**
- Taux d'erreur au niveau des mots
- 0.0 = parfait, 1.0 = toutes erreurs

**5. SSIM (Structural Similarity Index)**
- Similarit√© structurelle entre images
- 1.0 = identique, 0.0 = compl√®tement diff√©rent

**6. PSNR (Peak Signal-to-Noise Ratio)**
- Ratio signal/bruit
- Plus haut = meilleur (typiquement 20-50 dB)

**7. LPIPS (Learned Perceptual Image Patch Similarity)**
- Similarit√© perceptuelle apprise
- Plus bas = meilleur (0.0 = identique)

**8. OCR Accuracy**
- Pourcentage de caract√®res correctement reconnus par OCR
- 1.0 = 100% correct

---

## üîÑ Flux de Donn√©es Complet

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    FLUX DE DONN√âES                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

1. DONN√âES BRUTES (IAM Dataset)
   ‚îÇ
   ‚îú‚îÄ XML Files (strokes)
   ‚îÇ  ‚îî‚îÄ Coordonn√©es absolues (x, y, eos)
   ‚îÇ
   ‚îú‚îÄ ASCII Files (transcriptions)
   ‚îÇ  ‚îî‚îÄ Texte brut
   ‚îÇ
   ‚îî‚îÄ Metadata (writer IDs)
      ‚îî‚îÄ Identifiants √©crivains

2. PR√âTRAITEMENT (prepare_data.py)
   ‚îÇ
   ‚îú‚îÄ Strokes
   ‚îÇ  ‚îî‚îÄ XML ‚Üí Offsets normalis√©s [dx, dy, eos]
   ‚îÇ
   ‚îú‚îÄ Textes
   ‚îÇ  ‚îî‚îÄ ASCII ‚Üí Indices dans alphabet
   ‚îÇ
   ‚îî‚îÄ Sauvegarde
      ‚îî‚îÄ NumPy arrays (.npy)

3. DATASET PYTORCH (GAN/dataset.py)
   ‚îÇ
   ‚îú‚îÄ Chargement .npy
   ‚îÇ
   ‚îú‚îÄ Conversion strokes ‚Üí images 128√ó128
   ‚îÇ  ‚îî‚îÄ PIL ImageDraw
   ‚îÇ
   ‚îî‚îÄ Transformation
      ‚îî‚îÄ Tensor + Normalisation [-1, 1]

4. ENTRA√éNEMENT (GAN/train.py)
   ‚îÇ
   ‚îú‚îÄ Batch: (images, text_indices)
   ‚îÇ
   ‚îú‚îÄ Generator
   ‚îÇ  ‚îî‚îÄ [noise + text] ‚Üí image g√©n√©r√©e
   ‚îÇ
   ‚îú‚îÄ Discriminator
   ‚îÇ  ‚îî‚îÄ [image + text] ‚Üí score r√©el/faux
   ‚îÇ
   ‚îî‚îÄ Loss & Backprop
      ‚îî‚îÄ Mise √† jour des poids

5. INF√âRENCE
   ‚îÇ
   ‚îú‚îÄ GAN (GAN/app.py)
   ‚îÇ  ‚îî‚îÄ Texte ‚Üí Image via mod√®le entra√Æn√©
   ‚îÇ
   ‚îî‚îÄ Rendu stylis√© (handwriting_renderer.py)
      ‚îî‚îÄ Texte ‚Üí Image via polices + effets

6. √âVALUATION
   ‚îÇ
   ‚îú‚îÄ G√©n√©ration de paires (r√©el, g√©n√©r√©)
   ‚îÇ
   ‚îú‚îÄ Calcul m√©triques
   ‚îÇ  ‚îú‚îÄ FID, KID (qualit√© visuelle)
   ‚îÇ  ‚îú‚îÄ CER, WER (reconnaissance)
   ‚îÇ  ‚îî‚îÄ SSIM, PSNR, LPIPS (similarit√©)
   ‚îÇ
   ‚îî‚îÄ Rapport JSON
```

---

## üìÅ Structure des Fichiers

```
GEN - Copie/
‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/                    # Dataset IAM brut
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ascii/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ lineStrokes/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ original-xml/
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ processed/              # Donn√©es pr√©process√©es
‚îÇ       ‚îú‚îÄ‚îÄ x.npy               # Strokes
‚îÇ       ‚îú‚îÄ‚îÄ x_len.npy           # Longueurs strokes
‚îÇ       ‚îú‚îÄ‚îÄ c.npy               # Transcriptions
‚îÇ       ‚îú‚îÄ‚îÄ c_len.npy           # Longueurs textes
‚îÇ       ‚îî‚îÄ‚îÄ w_id.npy            # IDs √©crivains
‚îÇ
‚îú‚îÄ‚îÄ GAN/
‚îÇ   ‚îú‚îÄ‚îÄ model.py                # Generator + Discriminator
‚îÇ   ‚îú‚îÄ‚îÄ dataset.py              # IAMDataset PyTorch
‚îÇ   ‚îú‚îÄ‚îÄ train.py                # Script d'entra√Ænement
‚îÇ   ‚îú‚îÄ‚îÄ app.py                  # Interface Streamlit GAN
‚îÇ   ‚îú‚îÄ‚îÄ checkpoints/            # Mod√®les entra√Æn√©s
‚îÇ   ‚îî‚îÄ‚îÄ samples/                # √âchantillons g√©n√©r√©s
‚îÇ
‚îú‚îÄ‚îÄ evaluation/
‚îÇ   ‚îú‚îÄ‚îÄ real/                   # Images r√©elles
‚îÇ   ‚îî‚îÄ‚îÄ gen/                   # Images g√©n√©r√©es
‚îÇ
‚îú‚îÄ‚îÄ prepare_data.py             # Pr√©paration dataset IAM
‚îú‚îÄ‚îÄ drawing.py                  # Utilitaires de rendu strokes
‚îú‚îÄ‚îÄ handwriting_renderer.py    # Rendu stylis√© (polices)
‚îú‚îÄ‚îÄ metrics.py                  # M√©triques d'√©valuation
‚îú‚îÄ‚îÄ evaluate_metrics.py         # Script d'√©valuation
‚îú‚îÄ‚îÄ prepare_evaluation_data.py  # Pr√©paration donn√©es √©valuation
‚îú‚îÄ‚îÄ check_data_rendering.py     # V√©rification rendu
‚îÇ
‚îî‚îÄ‚îÄ streamlit_app.py            # Interface principale (rendu stylis√©)
```

---

## üéØ Points Cl√©s de l'Architecture

### 1. **Repr√©sentation des Strokes**
- Format : Offsets normalis√©s `[dx, dy, eos]`
- Avantages :
  - Invariant √† la translation
  - Normalis√© pour stabilit√©
  - Compact (1200 points max)

### 2. **Conditionnement du GAN**
- Le texte est embedd√© et concat√©n√© au bruit
- Le discriminateur re√ßoit aussi le texte
- Permet un contr√¥le pr√©cis de la g√©n√©ration

### 3. **Rendu On-the-Fly**
- Les strokes sont convertis en images √† la vol√©e dans le dataset
- √âvite de stocker des milliers d'images
- Permet des transformations dynamiques

### 4. **Deux Approches Compl√©mentaires**
- **GAN** : Apprentissage profond, style variable
- **Rendu stylis√©** : Contr√¥le pr√©cis, rapide, pas d'entra√Ænement

### 5. **√âvaluation Multi-M√©triques**
- Qualit√© visuelle (FID, KID)
- Reconnaissance (CER, WER, OCR)
- Similarit√© (SSIM, PSNR, LPIPS)

---

## üöÄ Workflow Typique

### **Entra√Ænement d'un nouveau mod√®le :**
```bash
# 1. Pr√©parer les donn√©es
python prepare_data.py

# 2. V√©rifier le rendu
python check_data_rendering.py

# 3. Entra√Æner le GAN
cd GAN
python train.py --epochs 100 --batch_size 16

# 4. G√©n√©rer des √©chantillons
# (automatique pendant l'entra√Ænement)
```

### **√âvaluation :**
```bash
# 1. Pr√©parer les donn√©es d'√©valuation
python prepare_evaluation_data.py

# 2. Calculer les m√©triques
python evaluate_metrics.py \
    --real_dir evaluation/real \
    --gen_dir evaluation/gen \
    --output metrics_results.json
```

### **Utilisation :**
```bash
# Interface Streamlit (rendu stylis√©)
streamlit run streamlit_app.py

# Interface GAN (si mod√®le entra√Æn√©)
streamlit run GAN/app.py
```

---

## üìà Hyperparam√®tres Principaux

| Param√®tre | Valeur | Description |
|-----------|--------|-------------|
| `image_size` | 128√ó128 | Taille des images g√©n√©r√©es |
| `latent_dim` | 100 | Dimension du vecteur de bruit |
| `text_embedding_dim` | 128 | Dimension de l'embedding texte |
| `max_text_len` | 20 | Longueur maximale du texte |
| `vocab_size` | ~70 | Taille de l'alphabet |
| `MAX_STROKE_LEN` | 1200 | Longueur max des s√©quences de strokes |
| `MAX_CHAR_LEN` | 75 | Longueur max des transcriptions |
| `learning_rate` | 0.0002 | Taux d'apprentissage |
| `batch_size` | 16 | Taille des batches |

---

## üîç D√©tails Techniques

### **Normalisation des Strokes**
- Les offsets sont normalis√©s par la m√©diane de leur norme
- √âvite les probl√®mes d'√©chelle
- Rend l'entra√Ænement plus stable

### **Padding et Truncation**
- Strokes : Padding avec `[0, 0, 0]` jusqu'√† `MAX_STROKE_LEN`
- Textes : Padding avec `0` (caract√®re nul) jusqu'√† `max_text_len`
- Les longueurs r√©elles sont stock√©es s√©par√©ment

### **Loss Function (LSGAN)**
- Utilise MSE au lieu de BCE
- Plus stable pour l'entra√Ænement
- Labels : `1` pour r√©el, `0` pour faux

### **Data Augmentation**
- Pas d'augmentation explicite dans le code actuel
- Possibilit√© d'ajouter : rotation, scaling, noise

---

## üéì Conclusion

Ce projet impl√©mente un pipeline complet de g√©n√©ration d'√©criture manuscrite, de la pr√©paration des donn√©es √† l'√©valuation, avec deux approches compl√©mentaires (GAN et rendu stylis√©) et une suite compl√®te de m√©triques d'√©valuation.

